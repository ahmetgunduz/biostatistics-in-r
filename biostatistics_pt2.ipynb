{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Approximation results and confidence intervals\n",
    "\n",
    "#### Law of Large Numbers\n",
    "\n",
    ">In probability theory, the **law of large numbers (LLN)** is a theorem that describes the result of performing the same experiment a large number of times. According to the law, the average of the results obtained from a large number of trials should be close to the expected value, and will tend to become closer as more trials are performed.\n",
    "\n",
    "> *Source: [Wikipedia](https://en.wikipedia.org/wiki/Law_of_large_numbers)*\n",
    "\n",
    "Imagine we are running an experiment to check the ratio of people with and w/o **Hypertension**. We assume that ratio from this dataset is true ratio of population. Then we take the sample of Hypertension results and check whether the difference between ratio of the sample and ratio of population is going to zero after bigger sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n <- 500\n",
    "\n",
    "#covert hypertension column to string on (0,1 integers)\n",
    "hypertension  <- as.numeric(levels(Stroke_Data$hypertension))[Stroke_Data$hypertension]\n",
    "\n",
    "avg_value <- mean(hypertension)\n",
    "\n",
    "#taking three random sample n-size each\n",
    "x1 = sample(hypertension, size = n, replace = F)\n",
    "x2 = sample(hypertension, size = n, replace = F)\n",
    "x3 = sample(hypertension, size = n, replace = F)\n",
    "\n",
    "#creating three vectors that will hold information about ratio for each size of sample (from 1 to n)\n",
    "xbar1 = rep(0,length(x1))\n",
    "xbar2 = rep(0,length(x2))\n",
    "xbar3 = rep(0,length(x3))\n",
    "\n",
    "for (i in 1:length(x1)) {\n",
    "    xbar1[i] = mean(x1[1:i])\n",
    "    xbar2[i] = mean(x2[1:i])\n",
    "    xbar3[i] = mean(x3[1:i])\n",
    "}\n",
    "\n",
    "plot(1:n, xbar1-avg_value, type=\"l\", col=\"red\", lwd=1, ylim=c(-0.1,0.2),\n",
    "     xlab=\"Number of subjects sampled\",\n",
    "     ylab=\"Distance to the mean\")\n",
    "lines(1:n, xbar2-avg_value, col=\"blue\", lwd=1)\n",
    "lines(1:n, xbar3-avg_value, col=\"orange\", lwd=1)\n",
    "lines(1:n, rep(0,n), lwd=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that the higher the number of subjects in our samples, the more likely mean of the sample is going to equal to the mean of population.\n",
    "\n",
    "The **law of large numbers** will establish that as *n* increases the averages are close to the target, while the\n",
    "**central limit theorem** will say how close and with what probability are the results of the experiment to the\n",
    "true target.\n",
    "\n",
    "#### Central Limit Theorem\n",
    "\n",
    "> In probability theory, the **central limit theorem (CLT)** establishes that, in some situations, when independent random variables are added, their properly normalized sum tends toward a normal distribution (informally a \"bell curve\") even if the original variables themselves are not normally distributed. The theorem is a key concept in probability theory because it implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions.\n",
    "\n",
    "> *Source: [Wikipedia](https://en.wikipedia.org/wiki/Central_limit_theorem)*\n",
    "\n",
    "Let's assume the **BMI** of people who had a **stroke** falls to normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bmi <- Stroke_Data$bmi[Stroke_Data$stroke == 1]\n",
    "\n",
    "n <- length(bmi)\n",
    "mu_hat <- mean(bmi) # Sample mean estimates the expected value (mu) \n",
    "s <- sd(bmi) # Sample standard deviation\n",
    "error <- s/sqrt(n) # The standard error of mu_hat\n",
    "z <- qnorm(0.05/2, lower.tail = F) # Compute the critical value z\n",
    "\n",
    "lower_ci <- mu_hat - z*error\n",
    "upper_ci <- mu_hat + z*error\n",
    "\n",
    "interval_estimate <- c(\"estimate\" = mu_hat, \"lower 95%\" = lower_ci, \"upper 95%\" = upper_ci)\n",
    "round(interval_estimate, digits = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist(bmi)\n",
    "abline(v = mean(bmi), col = \"royalblue\", lwd = 2)\n",
    "abline(v = lower_ci, col = \"red\", lwd = 2)\n",
    "abline(v = upper_ci, col = \"red\", lwd = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N <- 100\n",
    "means <- numeric(N)\n",
    "\n",
    "for(i in 1:N) {\n",
    "  bmi_sample <- sample(Stroke_Data$bmi[Stroke_Data$stroke == 1], size = 50, replace = F)\n",
    "  means[i] <- mean(bmi_sample)\n",
    "}\n",
    "\n",
    "# Compute basic summary statistics\n",
    "summary(means)\n",
    "\n",
    "# Visualize the distribution of the means with a histogram\n",
    "hist(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw a single sample of n = 50 exam points\n",
    "n <- 600\n",
    "bmi_sample <- sample(Stroke_Data$bmi[Stroke_Data$stroke == 1], size = n, replace = F)\n",
    "\n",
    "# Compute the sample mean\n",
    "mu_hat <- mean(bmi_sample)\n",
    "\n",
    "# Compute the sample standard deviation\n",
    "s <- sd(bmi_sample)\n",
    "\n",
    "# Compute the standard error of the mean\n",
    "error <- s/ sqrt(n)\n",
    "\n",
    "# (1) Histogram of the previously simulated sample means and\n",
    "# (2) The normal approximation of that distribution, based on a single sample\n",
    "hist(means, freq = F); \n",
    "curve(dnorm(x, mean = mu_hat, sd = error), add = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Introduction to t-test and confidence intervals\n",
    "\n",
    "Let's assume that we want to check whether the difference in age for people who had stroke and who didn't is significant. To do that we can run a **t-test** to find out.\n",
    "\n",
    ">The **t-test** (also called **Studentâ€™s T-Test**) compares two averages (means) and tells you if they are different from each other. The t-test also tells you how significant the differences are; In other words it lets you know if those differences could have happened by chance.\n",
    "\n",
    ">*Source: [Statistics How To](http://www.statisticshowto.com/probability-and-statistics/t-test/)*\n",
    "\n",
    "First, lets visually inspect the distribution of **Age** by **Stroke** outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Stroke_Data %>%\n",
    "    mutate(group = case_when(\n",
    "        (stroke == 1) ~ \"Stroke\",\n",
    "        (stroke == 0) ~ \"No Stroke\")) %>%\n",
    "    group_by(group) %>%\n",
    "    summarise(count = length(age),\n",
    "              mean = round(mean(age)),\n",
    "              variance = round(var(age),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can see is that average age for having a stroke is much higher (which should not come as a big surprise). If we compare the average values of two groups we will get: \n",
    "\\begin{align} \n",
    "\\mu^0- \\mu^1 = 41 - 68 = -27 \n",
    "\\end{align}\n",
    "\n",
    "Our hypothesis for **t-test** look like this:\n",
    "\n",
    "* $H_0$: there is no difference in mean between two groups. $\\mu^0 = \\mu^1$\n",
    "\n",
    "* $H_1$: there is a difference in mean between two groups. $\\mu^0 \\neq \\mu^1$\n",
    "\n",
    "Now we can just have to run `t.test` function which is built in in R and find out if our difference in means can be considered as significant or it's just a random chance. We can not use paired t-test vecause our groups have different samle size, so we have to set `paired = FALSE` (which comes as default). Another parameter `var.equal` should be also set to `FALSE` since variances between groups are not equal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t.test(age~stroke, \n",
    "       data=Stroke_Data,\n",
    "       var.equal = FALSE,\n",
    "       paired = FALSE,      \n",
    "       conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence interval of mean differences is: [-28; -26]. This does not include 0, so we **reject** null hypothesis and we say that there is a significance difference between group means with confidence level of 95%. In other words, **we are 95% confident that stroke is more likely to happen to older people**.\n",
    "\n",
    "This may seems unclear - we had two samples, calculated the difference of their averages. This difference was far away from 0, so why did we still have to run t-test to check fot significance? The answer is that the size of confidence interval depends on the sample size (the higher observations we have the more confident we can be). Let's run an another example with less amount of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example <- Stroke_Data %>%\n",
    "    select(stroke, age) \n",
    "\n",
    "#I will fill out data frame with unreal values just for example\n",
    "example  <- example[1:50,]\n",
    "example$stroke[1:25]  <- 0\n",
    "example$stroke[26:50] <- 1\n",
    "\n",
    "example %>% group_by(stroke) %>%\n",
    "    summarise(count = length(age),\n",
    "              mean_age = round(mean(age)),\n",
    "              variance = round(var(age),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t.test(age~stroke, \n",
    "       data=example,\n",
    "       var.equal = FALSE,\n",
    "       paired = FALSE,      \n",
    "       conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case difference was 9, which also can be considered as \"away from zero\", but confidence interval is too wide [-4; 21]. It includes 0 value, so we can not be so sure, that Age is not related to Stroke outcome based on these samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
